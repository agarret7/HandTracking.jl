* Robust Bayesian Hand-Tracking using Gen
  
** Purpose

  Template for more advanced projects seeking to leverage Bayesian methods for hand-tracking.
  Demonstration of the utility of Bayesian methods in a real-world problem domain.
  Teaching resource for learners eager to apply probabilistic methods to computer vision.
  Focus is on modularity/interpretability to encourage experimentation in Gen.

  Have a better RoI extractor? Plug it in to roi_extractor.py
  Want to write a more advanced localizer? Plug it in to localizer.py

  Run it all: docker build && docker run
  API: submit image, clear inference memory
  Returns: hand graph [json]

  For javascript bugs, some helpers in js
  Enable vis with --debug flag

** TODO Implement Robust Bayesian Hand-Tracking using Gen [33%]
   - [X] camera [2/2]
     - [X] gen_frame() : Unit -> Image
     - [X] generate test frames
   - [X] visualization [5/5]
     - [X] draw_roi : Image, RoI -> Image
     - [X] draw_segmentation : Image, SegMap -> Image
     - [X] render_heatmap : NeuralPixelScoreMap -> Image
     - [X] embed_subframe : Image, Image -> Image
     - [X] imshow : Image -> Unit
   - [ ] neural roi extractor [0/6]
     - [ ] set up tensorboard (may have to do next step concurrently)
     - [ ] data collection, conversion [?], verification, and testing
     - [ ] model implementation
     - [ ] training procedure
     - [ ] test performance and iterate
     - [ ] roi extractor code
   - [ ] visualization
     - [ ] render_hand : RoI, segmentation, reticle
   - [ ] Vague next steps
     - [ ] struct Hand
     - [ ] IDENTITY_HAND
     - [ ] handToMesh: Hand -> Mesh
     - [ ] render_hand : Hand -> Image
   - [ ] Web service
     - [ ] Inference server accepts image via HTTP
     - [ ] Web interface (started via DEBUG flag in julia, which starts a python web server)

** Design

*** Main server

*** Neural RoI Extractor

   Identify a square region localized around the hand.

   Inputs: hypothesized pose, depth image, camera metadata
   Outputs: roi bounds, segmentation map (?)

*** Amortized pose initializer

   Inputs: roi depth image, num samples
   Outputs: [hand graph]

*** Pose refinement

   Inputs: model, roi depth image
   Outputs: hand graph
